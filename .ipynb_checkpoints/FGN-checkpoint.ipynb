{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Input, Conv2D, Concatenate\n",
    "from keras.models import Model\n",
    "from keras.utils import plot_model\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger, LambdaCallback\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from matplotlib import pyplot as plt\n",
    "import keras.backend as K\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import shutil\n",
    "from PIL import Image\n",
    "batch_size = 1\n",
    "epochs = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4000 validated image filenames.\n",
      "Found 4000 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(r\"placesData.csv\")\n",
    "datagen = ImageDataGenerator(rescale=1./255, validation_split=.2)\n",
    "seed = 42\n",
    "image_generator = datagen.flow_from_dataframe(df, \n",
    "                                      directory='.', \n",
    "                                      x_col='x_train', \n",
    "                                      y_col='y_train', \n",
    "                                      batch_size=batch_size,\n",
    "                                      target_size=(512, 512),\n",
    "                                      class_mode=None, \n",
    "                                      seed=seed)\n",
    "mask_generator = datagen.flow_from_dataframe(df, \n",
    "                                     directory='.', \n",
    "                                     x_col='y_train', \n",
    "                                     y_col='x_train', # Or whatever \n",
    "                                     batch_size=batch_size,\n",
    "                                     target_size=(512, 512),\n",
    "                                     class_mode=None, \n",
    "                                     seed=seed)\n",
    "\n",
    "train_generator = zip(image_generator, mask_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21484375\n",
      "(1, 512, 512, 1)\n"
     ]
    }
   ],
   "source": [
    "mask = np.zeros((512,512,1))\n",
    "for i in range(0, 512):\n",
    "    for j in range(0, 512):\n",
    "        if ((i-255)**2+(j-255)**2)**.5 > 32:\n",
    "            mask[i,j,0] = ((i-255)**2+(j-255)**2)**.5\n",
    "mask = (mask - mask.min()) / (mask.max() - mask.min())\n",
    "print(mask[0][0][0])\n",
    "print(mask[255][287][0])\n",
    "print(mask[255][288][0])\n",
    "inputMask = mask[None, :]\n",
    "inputMask = np.tile(mask, (batch_size,1,1,1))\n",
    "tMask = K.variable(inputMask)\n",
    "inputMask = Input(tensor=tMask)\n",
    "print(tMask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 512, 512, 4)\n",
      "(1, 512, 512, 256)\n",
      "(1, 512, 512, 512)\n",
      "(1, 512, 512, 512)\n",
      "(1, 512, 512, 3)\n"
     ]
    }
   ],
   "source": [
    "input = Input(shape=(512, 512, 3,), batch_shape=(batch_size, 512, 512, 3))\n",
    "im = Concatenate(axis=-1)([input, inputMask])\n",
    "print (im.shape)\n",
    "l1 = Conv2D(filters=256, kernel_size=(16, 16), padding=\"same\", activation='tanh')(im)\n",
    "print(l1.shape)\n",
    "l2 = Conv2D(filters=512, kernel_size=(8, 8), padding=\"same\", activation='tanh')(l1)\n",
    "print(l2.shape)\n",
    "l3 = Conv2D(filters=512, kernel_size=(1, 1), padding=\"same\", activation='tanh')(l2)\n",
    "print(l3.shape)\n",
    "output = Conv2D(filters=3, kernel_size=(8, 8), padding=\"same\", activation='sigmoid')(l3)\n",
    "print(output.shape)\n",
    "model = Model(inputs=[input, inputMask], outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[119. 128. 111.]\n",
      "  [106. 115.  98.]\n",
      "  [ 73.  80.  62.]\n",
      "  ...\n",
      "  [129. 114. 109.]\n",
      "  [107.  89.  85.]\n",
      "  [107.  89.  85.]]\n",
      "\n",
      " [[128. 136. 121.]\n",
      "  [113. 120. 104.]\n",
      "  [ 81.  88.  72.]\n",
      "  ...\n",
      "  [120. 107.  99.]\n",
      "  [110.  95.  90.]\n",
      "  [104.  89.  84.]]\n",
      "\n",
      " [[107. 113.  99.]\n",
      "  [101. 107.  93.]\n",
      "  [ 86.  90.  75.]\n",
      "  ...\n",
      "  [130. 120. 111.]\n",
      "  [129. 119. 110.]\n",
      "  [116. 103.  97.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[167. 137. 145.]\n",
      "  [168. 138. 146.]\n",
      "  [168. 138. 146.]\n",
      "  ...\n",
      "  [236. 220. 231.]\n",
      "  [232. 216. 227.]\n",
      "  [229. 213. 224.]]\n",
      "\n",
      " [[164. 137. 142.]\n",
      "  [152. 125. 130.]\n",
      "  [149. 122. 127.]\n",
      "  ...\n",
      "  [227. 212. 215.]\n",
      "  [226. 210. 213.]\n",
      "  [225. 209. 210.]]\n",
      "\n",
      " [[181. 154. 159.]\n",
      "  [164. 137. 142.]\n",
      "  [153. 126. 131.]\n",
      "  ...\n",
      "  [225. 210. 213.]\n",
      "  [221. 205. 208.]\n",
      "  [215. 199. 200.]]]\n"
     ]
    }
   ],
   "source": [
    "img = image.load_img(\"places/s00001.png\", grayscale=False, target_size=(512, 512))\n",
    "x = np.array(image.img_to_array(img))\n",
    "print(x)\n",
    "x = x[None, :]/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = optimizers.SGD(lr=0.004, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=sgd,\n",
    "             loss='mean_squared_error',\n",
    "             metrics=['accuracy', 'mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "100/100 [==============================] - 871s 9s/step - loss: 0.0341 - accuracy: 0.6273 - mse: 0.0341\n",
      "\n",
      "Epoch 00001: saving model to FGNchkpt.hdf5\n",
      "[[[108.78995  114.63767  112.8775  ]\n",
      "  [106.73418  113.46447  110.9348  ]\n",
      "  [103.4557   108.20896  104.271645]\n",
      "  ...\n",
      "  [125.40934  120.3579   122.515976]\n",
      "  [125.02415  121.115036 121.857605]\n",
      "  [122.380516 120.03733  122.67607 ]]\n",
      "\n",
      " [[105.60192  110.78981  110.043976]\n",
      "  [102.95491  108.617714 107.70334 ]\n",
      "  [ 99.60696  103.529884 100.24425 ]\n",
      "  ...\n",
      "  [126.257324 124.29247  124.511696]\n",
      "  [124.992805 124.71871  122.75732 ]\n",
      "  [121.117805 121.5121   122.39569 ]]\n",
      "\n",
      " [[103.70575  105.826614 107.1817  ]\n",
      "  [100.41154  102.32055  104.03875 ]\n",
      "  [ 96.879074  98.40683   97.35155 ]\n",
      "  ...\n",
      "  [128.72218  127.54967  128.89032 ]\n",
      "  [126.70046  125.406075 125.42766 ]\n",
      "  [122.77238  121.056656 125.00033 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[128.34412  120.865555 118.06768 ]\n",
      "  [130.62273  120.11068  117.229454]\n",
      "  [130.78096  120.368805 116.84708 ]\n",
      "  ...\n",
      "  [135.67682  142.4072   148.13054 ]\n",
      "  [134.2687   138.50024  144.84142 ]\n",
      "  [131.3747   132.71457  137.14915 ]]\n",
      "\n",
      " [[124.48524  118.67712  116.82124 ]\n",
      "  [125.35478  118.55669  114.404816]\n",
      "  [124.04087  119.65731  114.1897  ]\n",
      "  ...\n",
      "  [129.88496  136.3189   144.49637 ]\n",
      "  [130.85973  132.9768   142.30429 ]\n",
      "  [129.74124  129.69331  135.80849 ]]\n",
      "\n",
      " [[123.14298  118.58938  115.564354]\n",
      "  [122.98784  119.10007  113.898674]\n",
      "  [121.60119  119.042175 112.90495 ]\n",
      "  ...\n",
      "  [124.949684 129.82231  135.79573 ]\n",
      "  [127.08701  128.45726  135.0109  ]\n",
      "  [125.78765  127.44786  132.81703 ]]]\n",
      "Epoch 2/400\n",
      "100/100 [==============================] - 837s 8s/step - loss: 0.0222 - accuracy: 0.7366 - mse: 0.0222\n",
      "\n",
      "Epoch 00002: saving model to FGNchkpt.hdf5\n",
      "[[[102.94651  108.98988  106.161545]\n",
      "  [100.56948  107.54159  103.49964 ]\n",
      "  [ 97.27617  102.07334   95.60592 ]\n",
      "  ...\n",
      "  [123.73616  115.63613  115.38025 ]\n",
      "  [121.5601   115.304726 114.23445 ]\n",
      "  [117.65533  113.643425 115.68207 ]]\n",
      "\n",
      " [[ 99.13152  104.892235 102.33622 ]\n",
      "  [ 96.224594 102.63116   99.20297 ]\n",
      "  [ 92.92389   97.42313   90.35407 ]\n",
      "  ...\n",
      "  [126.90402  121.621254 118.20182 ]\n",
      "  [122.69825  120.024185 115.35062 ]\n",
      "  [116.62327  115.29362  115.31652 ]]\n",
      "\n",
      " [[ 96.647316  99.15522   98.18071 ]\n",
      "  [ 93.13971   95.48123   94.119934]\n",
      "  [ 89.694016  91.346756  85.9815  ]\n",
      "  ...\n",
      "  [131.31442  126.039055 122.74606 ]\n",
      "  [125.31694  121.129906 117.48869 ]\n",
      "  [118.51318  114.652176 117.17664 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[126.09695  119.754845 116.21714 ]\n",
      "  [129.42586  120.29325  116.13045 ]\n",
      "  [130.48701  121.82455  116.64204 ]\n",
      "  ...\n",
      "  [142.28073  147.01399  151.39806 ]\n",
      "  [136.53645  140.16985  145.27135 ]\n",
      "  [130.66284  131.96167  135.59901 ]]\n",
      "\n",
      " [[120.15776  115.17445  112.952644]\n",
      "  [121.21653  115.62849  110.61981 ]\n",
      "  [119.76589  117.23353  110.59114 ]\n",
      "  ...\n",
      "  [132.02316  137.4136   145.66782 ]\n",
      "  [130.28406  132.50099  141.53223 ]\n",
      "  [127.45588  127.930565 133.79376 ]]\n",
      "\n",
      " [[117.34404  113.42313  110.90234 ]\n",
      "  [116.622215 113.74646  108.68446 ]\n",
      "  [114.63142  113.18783  107.16255 ]\n",
      "  ...\n",
      "  [123.04791  127.33638  133.64407 ]\n",
      "  [123.73484  125.4283   132.29922 ]\n",
      "  [122.08661  124.297455 129.81026 ]]]\n",
      "Epoch 3/400\n",
      "100/100 [==============================] - 838s 8s/step - loss: 0.0134 - accuracy: 0.7591 - mse: 0.0134\n",
      "\n",
      "Epoch 00003: saving model to FGNchkpt.hdf5\n",
      "[[[104.11692  110.776764 108.34537 ]\n",
      "  [103.06317  110.85117  107.05085 ]\n",
      "  [101.12496  106.79025  100.197334]\n",
      "  ...\n",
      "  [127.61469  120.09556  118.33376 ]\n",
      "  [124.4377   117.57291  115.622635]\n",
      "  [118.91591  114.77498  115.93274 ]]\n",
      "\n",
      " [[101.1218   108.24026  104.813705]\n",
      "  [ 99.758156 107.828354 103.55327 ]\n",
      "  [ 98.11905  104.30621   95.90823 ]\n",
      "  ...\n",
      "  [132.3364   127.13993  121.34239 ]\n",
      "  [127.03032  123.02963  116.98579 ]\n",
      "  [118.86864  116.9533   115.31767 ]]\n",
      "\n",
      " [[ 99.219666 103.74494  101.3063  ]\n",
      "  [ 97.578766 101.99375   99.54803 ]\n",
      "  [ 96.01579   99.63941   93.04856 ]\n",
      "  ...\n",
      "  [137.45468  131.78134  126.2612  ]\n",
      "  [130.28258  124.21165  119.45249 ]\n",
      "  [121.06618  116.38066  117.48098 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[125.09315  121.19575  116.82425 ]\n",
      "  [128.99161  121.377716 117.39378 ]\n",
      "  [130.84412  123.8026   118.50793 ]\n",
      "  ...\n",
      "  [144.73128  146.21805  149.38058 ]\n",
      "  [138.51352  139.60098  143.94772 ]\n",
      "  [131.0441   130.78203  134.40738 ]]\n",
      "\n",
      " [[119.50923  115.304306 112.90352 ]\n",
      "  [121.03488  115.464455 111.04202 ]\n",
      "  [120.12399  117.54093  111.339165]\n",
      "  ...\n",
      "  [133.5068   136.47867  143.99364 ]\n",
      "  [131.22768  132.0598   140.24077 ]\n",
      "  [127.11652  126.75067  132.58989 ]]\n",
      "\n",
      " [[116.14915  113.350525 110.90896 ]\n",
      "  [115.74568  113.439354 109.39716 ]\n",
      "  [114.18168  113.06403  108.040634]\n",
      "  ...\n",
      "  [123.31699  126.45682  132.49313 ]\n",
      "  [123.61259  125.21451  131.28532 ]\n",
      "  [121.314835 123.25187  128.64702 ]]]\n",
      "Epoch 4/400\n",
      " 73/100 [====================>.........] - ETA: 3:46 - loss: 0.0097 - accuracy: 0.7630 - mse: 0.0097"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(\"FGNchkpt.hdf5\", monitor='loss', save_best_only=False, mode='auto', period=1, verbose=1)\n",
    "csv_logger = CSVLogger('training.log')\n",
    "image_saver = LambdaCallback(on_epoch_end=lambda epoch,logs: Image.fromarray((model.predict(x)[0]*255.).astype('uint8')).save(\"eImgs/\"+str(epoch)+\"p.jpeg\"))\n",
    "sanity_check1 = LambdaCallback(on_epoch_end=lambda epoch,logs: print((model.predict(x)[0]*255.)))\n",
    "model.fit_generator(train_generator, steps_per_epoch=100/batch_size, epochs=epochs, shuffle=True, callbacks=[checkpoint, csv_logger, image_saver, sanity_check1], verbose=1)\n",
    "model.save('FGNweights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_weights(\"FGNchkpt.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.load_img(\"places/s00001.png\", grayscale=False, target_size=(512, 512))\n",
    "x = np.array(image.img_to_array(img))\n",
    "print(x)\n",
    "x = x[None, :]\n",
    "#print(na.shape)\n",
    "y = model.predict(x/255.)\n",
    "plt.imshow(x[0]/255.)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image_generator.next()[0][0][255])\n",
    "print(mask_generator.next()[0][0][255])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
